{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66228e65",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Run everything in order to generate the images and accuracy estimates. The model can be modified by specifying `k_sigma` (immediately after Modeling heading).\n",
    "\n",
    "Information about the data can be found here: [NHANES 2017-2020 Survey Homepage](https://wwwn.cdc.gov/Nchs/Nhanes/continuousnhanes/default.aspx?cycle=2017-2020)\n",
    "\n",
    "An outline of this notebook is as follows:\n",
    "- Function Definitions: defining the functions that compute the distributions/binomial parameters\n",
    "- Data Collection and Preprocessing: pulls the data, cleans it, and does a train-test split\n",
    "- Train-Test Split Visualization: plots the distribution of the train and test data\n",
    "- Modeling: where the binomial distributions are computed and modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885630bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.special import binom\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499bc780",
   "metadata": {},
   "outputs": [],
   "source": [
    "lirio_brand_colors = ['#F06923','#0A4150','#FEC010','#4A707A','#B9561D','#C9D4D7','#F59105']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc3ea3a",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461d67d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that define probabilities and sample sizes and compute binomial coefficients\n",
    "def probabilities(k,s):\n",
    "    if k <= 0:\n",
    "        return s\n",
    "    elif 1 - (s / k) <= 0:\n",
    "        return 0.00001\n",
    "    else:\n",
    "        return 1 - (s / k)\n",
    "    \n",
    "def samples(k,p):\n",
    "    if k <= 0:\n",
    "        return 1\n",
    "    elif p <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return k / p\n",
    "    \n",
    "def binomial_coefficient(n,p,k):\n",
    "    if k > np.round(n,0):\n",
    "        return 0.\n",
    "    elif p >= 1:\n",
    "        if np.round(n,0) == k:\n",
    "            return 1.\n",
    "        else:\n",
    "            return 0.\n",
    "    elif p <= 0:\n",
    "        if k <= 0:\n",
    "            return 1.\n",
    "        else:\n",
    "            return 0.\n",
    "    else:\n",
    "        return binom(n,k)*np.power(p,k)*np.power(1. - p,n-k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e8ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_binomial_parameters(k_sigma_vals,response):\n",
    "    \n",
    "    # Split k and sigma values\n",
    "    k_vals = [ksig[0] for ksig in k_sigma_vals]\n",
    "    sigma_vals = [ksig[1] for ksig in k_sigma_vals]\n",
    "    \n",
    "    # Compute probabilities\n",
    "    p_vals = [probabilities(i[0],i[1]) for i in k_sigma_vals]\n",
    "    \n",
    "    # Compute samples\n",
    "    n_vals = [samples(i[0],i[1]) for i in zip(k_vals,p_vals)]\n",
    "#     n_vals = [np.round(n,0) for n in n_vals]\n",
    "    \n",
    "    # Compute weights\n",
    "    binom_coefs = [[binomial_coefficient(n,p,k) for p,n in zip(p_vals,n_vals)] for k in k_vals]\n",
    "    binom_coefs.append([1.] * len(k_vals))\n",
    "    w_response = [response['prob'].loc[np.round(k,0)] for k in k_vals] + [1.]\n",
    "    reg = LinearRegression(fit_intercept = False).fit(binom_coefs,w_response)\n",
    "    \n",
    "    return n_vals,p_vals,reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d205a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distribution(n_vals,p_vals,weights):\n",
    "    dfg = pd.DataFrame(\n",
    "        data = zip(\n",
    "            n_vals,\n",
    "            p_vals\n",
    "        ),\n",
    "        columns = ['sample','success'],\n",
    "        index = [f'k{i}' for i in range(1,1+len(n_vals))]\n",
    "    )\n",
    "\n",
    "    binomial_df = pd.DataFrame(\n",
    "        data = range(22),\n",
    "        columns = ['k']\n",
    "    )\n",
    "\n",
    "    for i in dfg.index:\n",
    "        binomial_df[i] = None\n",
    "        n = dfg['sample'].loc[i]\n",
    "        p = dfg['success'].loc[i]\n",
    "        binomial_df[i] = [binomial_coefficient(n,p,k) for k in np.linspace(0,21,22)]\n",
    "\n",
    "    binomial_df['prob'] = binomial_df.apply(lambda x: np.dot(weights,x[1:]), axis = 1)\n",
    "\n",
    "    return binomial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6687ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_scale(\n",
    "    p_vals,\n",
    "    n_vals,\n",
    "    k_sigma_vals,\n",
    "    response\n",
    "):\n",
    "    \n",
    "    k_vals = [ksig[0] for ksig in k_sigma_vals]\n",
    "    \n",
    "    # Compute weights\n",
    "    binom_coefs = [[binomial_coefficient(n,p,k) for p,n in zip(p_vals,n_vals)] for k in k_vals]\n",
    "    binom_coefs.append([1.] * len(k_vals))\n",
    "    w_response = [response['prob'].loc[np.round(k,0)] for k in k_vals] + [1.]\n",
    "    reg = LinearRegression(fit_intercept = False).fit(binom_coefs,w_response)\n",
    "    \n",
    "    return reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_probabilities(\n",
    "    p_vals,\n",
    "    n_vals,\n",
    "    weights,\n",
    "    k_sigma_vals,\n",
    "    response,\n",
    "    factor_scale = 0.1,\n",
    "    factor_direction = 1,\n",
    "    variable = 'gender_male',\n",
    "    new_scale = False,\n",
    "):\n",
    "    \n",
    "    zero_p_vals = [max(min((1-factor_direction * factor_scale)*(p-0.5)+0.5,1),0) for p in p_vals]\n",
    "    one_p_vals = [max(min((1+factor_direction * factor_scale)*(p-0.5)+0.5,1),0) for p in p_vals]\n",
    "    \n",
    "    print(f\"0: {', '.join([f'$p_{i}^f={np.round(zero_p_vals[i],3)}$'for i in range(len(zero_p_vals))])}\")\n",
    "    print(f\"1: {', '.join([f'$p_{i}^m={np.round(one_p_vals[i],3)}$'for i in range(len(one_p_vals))])}\")\n",
    "    \n",
    "    original_binomial_df = generate_distribution(n_vals,p_vals,weights)\n",
    "    original_binomial_df['num_meals_not_home'] = original_binomial_df['k']\n",
    "    original_binomial_df[variable] = 'Original'\n",
    "    original_binomial_df['data'] = 'original'\n",
    "    \n",
    "    if new_scale:\n",
    "        zero_weights = generate_new_scale(\n",
    "            zero_p_vals,\n",
    "            n_vals,\n",
    "            k_sigma_vals,\n",
    "            response\n",
    "        )\n",
    "    else:\n",
    "        zero_weights = weights\n",
    "    \n",
    "    zero_binomial_df = generate_distribution(n_vals,zero_p_vals,zero_weights)\n",
    "    zero_binomial_df[variable] = feature_dict[variable][0]\n",
    "    zero_binomial_df['num_meals_not_home'] = zero_binomial_df['k']\n",
    "    zero_binomial_df['data'] = 'modified'\n",
    "    \n",
    "    if new_scale:\n",
    "        one_weights = generate_new_scale(\n",
    "            one_p_vals,\n",
    "            n_vals,\n",
    "            k_sigma_vals,\n",
    "            response\n",
    "        )\n",
    "    else:\n",
    "        one_weights = weights\n",
    "        \n",
    "    one_binomial_df = generate_distribution(n_vals,one_p_vals,one_weights)\n",
    "    one_binomial_df[variable] = feature_dict[variable][1]\n",
    "    one_binomial_df['num_meals_not_home'] = one_binomial_df['k']\n",
    "    one_binomial_df['data'] = 'modified'\n",
    "    \n",
    "    return original_binomial_df,zero_binomial_df,one_binomial_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ffd169",
   "metadata": {},
   "source": [
    "# Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0b9b49",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "1. Pull data from website\n",
    "2. Label columns with readable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77ad5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic Data Column Name Meanings\n",
    "demo_names_url = 'https://wwwn.cdc.gov/Nchs/Nhanes/search/variablelist.aspx?Component=Demographics&Cycle=2017-2020'\n",
    "\n",
    "# Demographic Data\n",
    "demo_url = 'https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_DEMO.XPT'\n",
    "\n",
    "# Survey Data Column Name Meanings\n",
    "survey_names_url = 'https://wwwn.cdc.gov/Nchs/Nhanes/search/variablelist.aspx?Component=Questionnaire&Cycle=2017-2020'\n",
    "\n",
    "# Survey Data\n",
    "survey_url = 'https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_DBQ.XPT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_names = pd.read_html(demo_names_url)[0]\n",
    "survey_names = pd.read_html(survey_names_url)[0]\n",
    "demo = pd.read_sas(demo_url)\n",
    "survey = pd.read_sas(survey_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a6a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo['SEQN'] = demo['SEQN'].astype(int)\n",
    "survey['SEQN'] = survey['SEQN'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce4ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_names_dict = demo_names.set_index('Variable Name')['Variable Description'].to_dict()\n",
    "demo_names_dict['SEQN'] = 'SEQN'\n",
    "\n",
    "survey_names_dict = survey_names.set_index('Variable Name')['Variable Description'].to_dict()\n",
    "survey_names_dict['SEQN'] = 'SEQN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c10ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.columns = [demo_names_dict[i] for i in demo.columns]\n",
    "survey.columns = [survey_names_dict[i] for i in survey.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f5162c",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "1. Pick columns of interest\n",
    "2. Drop missing values from demographic data\n",
    "3. Correct missing values in number of fast food meals\n",
    "4. Drop missing values from survey data\n",
    "5. Merge demographic and survey data\n",
    "6. Drop values out of acceptable range\n",
    "7. Convert coded values to readable values\n",
    "8. One-hot encode categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7548f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_small = demo[[\n",
    "    'SEQN',\n",
    "    'Gender of the participant.',\n",
    "    'Age in years of the participant at the time of screening. Individuals 80 and over are topcoded at 80 years of age.',\n",
    "    'Recode of reported race and Hispanic origin information, with Non-Hispanic Asian Category',\n",
    "    'What is the highest grade or level of school {you have/SP has} completed or the highest degree {you have/s/he has} received?',\n",
    "    'Marital status',\n",
    "    'A ratio of family income to poverty guidelines.'\n",
    "]].copy(deep = True).dropna()\n",
    "demo_small.columns = [\n",
    "    'SEQN',\n",
    "    'gender',\n",
    "    'age',\n",
    "    'race',\n",
    "    'education',\n",
    "    'marital_status',\n",
    "    'income'\n",
    "]\n",
    "\n",
    "for col in demo_small.columns:\n",
    "    demo_small[col] = demo_small[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_small = survey[[\n",
    "    'SEQN',\n",
    "    \"Next I'm going to ask you about meals. By meal, I mean breakfast, lunch and dinner. During the past 7 days, how many meals {did you/did SP} get that were prepared away from home in places such as restaurants, fast food places, food stands, grocery stores, or from vending machines? {Please do not include meals provided as part of the school lunch or school breakfast./Please do not include meals provided as part of the community programs you reported earlier.}\",\n",
    "    'How many of those meals {did you/did SP} get from a fast-food or pizza place?',\n",
    "    'Some grocery stores sell \"ready to eat\" foods such as salads, soups, chicken, sandwiches and cooked vegetables in their salad bars and deli counters. During the past 30 days, how often did {you/SP} eat \"ready to eat\" foods from the grocery store? Please do not include sliced meat or cheese you buy for sandwiches and frozen or canned foods.',\n",
    "    'During the past 30 days, how often did you {SP} eat frozen meals or frozen pizzas? Here are some examples of frozen meals and frozen pizzas.'\n",
    "]].copy(deep = True)#.dropna()\n",
    "survey_small.columns = [\n",
    "    'SEQN',\n",
    "    'num_meals_not_home',\n",
    "    'num_meals_fast_food',\n",
    "    'num_ready_foods_30_days',\n",
    "    'num_frozen_foods_30_days'\n",
    "]\n",
    "\n",
    "# Drop rows with missing `num_meals_not_home`\n",
    "survey_small = survey_small[~survey_small['num_meals_not_home'].isna()]\n",
    "survey_small['num_meals_not_home'] = survey_small['num_meals_not_home'].astype(int)\n",
    "\n",
    "# If `num_meals_not_home` is 0 and `num_meals_fast_food` is missing, replace missing value with 0\n",
    "survey_small.loc[\n",
    "    survey_small[\n",
    "        (survey_small['num_meals_fast_food'].isna()) &\n",
    "        (survey_small['num_meals_not_home'] == 0)\n",
    "    ].index,\n",
    "    'num_meals_fast_food'\n",
    "] = 0\n",
    "\n",
    "# Drop rows with missing values\n",
    "survey_small.dropna(inplace = True)\n",
    "\n",
    "# Converting these to integers, which `num_meals_not_home` and `num_meals_fast_food` may not be\n",
    "for col in survey_small.columns:\n",
    "    survey_small[col] = survey_small[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92211883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    demo_small,\n",
    "    survey_small,\n",
    "    on='SEQN'\n",
    ").set_index('SEQN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fad2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unknowns education\n",
    "df.drop(df[df['education'].isin([7,9])].index, inplace = True)\n",
    "\n",
    "# Drop unknown marital status\n",
    "df.drop(df[df['marital_status'].isin([77,99])].index, inplace = True)\n",
    "\n",
    "# Drop out of range number of meals eaten, not prepared at home\n",
    "df.drop(df[df['num_meals_not_home'] > 21].index, inplace = True)\n",
    "df.drop(df[df['num_meals_fast_food'] > df['num_meals_not_home']].index, inplace = True)\n",
    "\n",
    "# Drop meals that are too high (I think it means unknown anyway)\n",
    "df.drop(df[df['num_ready_foods_30_days'] > 90].index, inplace = True)\n",
    "\n",
    "# Drop meals that are too high\n",
    "df.drop(df[df['num_frozen_foods_30_days'] > 90].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc430b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature value names from https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_DEMO.htm\n",
    "gender_dict = {\n",
    "    1: 'male',\n",
    "    2: 'female'\n",
    "}\n",
    "\n",
    "race_dict = {\n",
    "    1: 'Minority', #'Mexican American',\n",
    "    2: 'Minority', #'Other Hispanic',\n",
    "    3: 'Majority', #'Non-Hispanic White',\n",
    "    4: 'Minority', #'Non-Hispanic Black',\n",
    "    6: 'Minority', #'Non-Hispanic Asian',\n",
    "    7: 'Minority', #'Other Race'\n",
    "}\n",
    "\n",
    "education_dict = {\n",
    "    1: 'Less than 9th grade',\n",
    "    2: '9-11th grade (Includes 12th grade with no diploma)',\n",
    "    3: 'High school graduate/GED or equivalent',\n",
    "    4: 'Some college or AA degree',\n",
    "    5: 'College graduate or above',\n",
    "    7: 'unknown',\n",
    "    9: 'unknown'\n",
    "}\n",
    "\n",
    "marital_dict = {\n",
    "    1: 'Married', #'Married/Living with Partner',\n",
    "    2: 'Single', #'Widowed/Divorced/Separated',\n",
    "    3: 'Single', #'Never married',\n",
    "    77: 'unknown',\n",
    "    99: 'unknown'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace coded values with their meaning\n",
    "df.gender = df.gender.map(gender_dict)\n",
    "df.race = df.race.map(race_dict)\n",
    "df.marital_status = df.marital_status.map(marital_dict)\n",
    "# Note: there are no 'unknown' values\n",
    "# We will keep education as an ordinal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca61142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "df_dummies = pd.get_dummies(df, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb4e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to convert from dummy variables to their meaning\n",
    "feature_dict = {\n",
    "    'marital_status_Single':{\n",
    "        0:'Married',\n",
    "        1:'Single'\n",
    "    },\n",
    "    'race_Minority':{\n",
    "        0: 'Majority',\n",
    "        1: 'Minority'\n",
    "    },\n",
    "    'gender_male':{\n",
    "        0: 'Female',\n",
    "        1: 'Male'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71415d9a",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dea970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "X_train, X_test, _, _ = train_test_split(\n",
    "    df_dummies,\n",
    "    df_dummies['num_meals_not_home'],\n",
    "    test_size=0.33,\n",
    "    random_state=330396\n",
    ")\n",
    "\n",
    "# Generate train distribution\n",
    "meals_train = X_train['num_meals_not_home'].value_counts(normalize = True).to_frame('prob').reset_index()\n",
    "meals_train.columns = ['k','prob']\n",
    "meals_train.sort_values('k', inplace = True)\n",
    "meals_train.reset_index(drop = True, inplace = True)\n",
    "meals_train['data'] = 'real'\n",
    "meals_train['split'] = 'train'\n",
    "\n",
    "# Generate test distribution\n",
    "meals_test = X_test['num_meals_not_home'].value_counts(normalize = True).to_frame('prob').reset_index()\n",
    "meals_test.columns = ['k','prob']\n",
    "meals_test.sort_values('k', inplace = True)\n",
    "meals_test.reset_index(drop = True, inplace = True)\n",
    "meals_test['data'] = 'real'\n",
    "meals_test['split'] = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c0b998",
   "metadata": {},
   "source": [
    "# Train-Test Split Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9291748",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (6,3))\n",
    "g = sns.lineplot(\n",
    "    data = meals_train,\n",
    "    x = 'k',\n",
    "    y = 'prob',\n",
    "    color = lirio_brand_colors[0],\n",
    "    linestyle = '-',\n",
    "    ax = ax\n",
    ")\n",
    "sns.lineplot(\n",
    "    data = meals_test,\n",
    "    x = 'k',\n",
    "    y = 'prob',\n",
    "    color = lirio_brand_colors[2],\n",
    "    linestyle = '-',\n",
    "    ax = ax\n",
    ")\n",
    "g.set_xticks(range(22))\n",
    "g.set_title('Train and Test Distributions From Dataset')\n",
    "g.set_xlabel('Number of Times Eaten Out')\n",
    "g.set_ylabel('Probability')\n",
    "ax.legend(\n",
    "    labels = ['Train', 'Test'],\n",
    "    title = 'Data Source'\n",
    ")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('data_distributions.png', dpi = 250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a352a7",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1727fbd7",
   "metadata": {},
   "source": [
    "## Simulate Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beeeae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_sigma = [\n",
    "    [0,0.2],\n",
    "    [2.,1],\n",
    "    [4,0.8],\n",
    "    [5,0.4],\n",
    "    [7.,0.4],\n",
    "    [10.,0.1],\n",
    "    [14,0.1],\n",
    "    [21,0.1]\n",
    "]\n",
    "\n",
    "ns,ps,scale = generate_binomial_parameters(k_sigma,meals_train)\n",
    "binomials = generate_distribution(ns,ps,scale)\n",
    "binomials['data'] = 'simulated'\n",
    "binomials['split'] = 'simulated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.concat([\n",
    "    binomials[['prob']],\n",
    "    meals_train[['prob']],\n",
    "    meals_test[['prob']]\n",
    "], axis = 1)\n",
    "acc.columns = ['sim','train','test']\n",
    "train_error = acc[['sim','train']].min(axis = 1).sum()\n",
    "test_error =  acc[['sim','test']].min(axis = 1).sum()\n",
    "print('Accuracy')\n",
    "print(F'Train H.I.: {np.round(train_error,3)}')\n",
    "print(F'Test H.I.: {np.round(test_error,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff479922",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (10,5))\n",
    "g = sns.lineplot(\n",
    "    data = binomials,\n",
    "    x = 'k',\n",
    "    y = 'prob',\n",
    "    color = lirio_brand_colors[1],\n",
    "    linestyle = '--',\n",
    "    ax = ax\n",
    ")\n",
    "sns.lineplot(\n",
    "    data = meals_train,\n",
    "    x = 'k',\n",
    "    y = 'prob',\n",
    "    color = lirio_brand_colors[0],\n",
    "    linestyle = '-',\n",
    "    ax = ax\n",
    ")\n",
    "sns.lineplot(\n",
    "    data = meals_test,\n",
    "    x = 'k',\n",
    "    y = 'prob',\n",
    "    color = lirio_brand_colors[2],\n",
    "    linestyle = '-',\n",
    "    ax = ax\n",
    ")\n",
    "g.set_xticks(range(22))\n",
    "g.set_title('Real and Simulated Distributions')\n",
    "g.set_xlabel('Number of Times Eaten Out')\n",
    "g.set_ylabel('Probability')\n",
    "ax.legend(\n",
    "    labels = ['Simulation', 'Train', 'Test'],\n",
    "    title = 'Data Source'\n",
    ")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "# plt.savefig('base_simulation.png', dpi = 250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae64aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_dict = {f'k{i}':f'$n_{i}={int(np.round(k_sigma[i-1][0],0))}$, $p_{i}={np.round(ps[i-1],3)}$' for i in range(1,8)}\n",
    "\n",
    "melted_binomials = pd.melt(\n",
    "    binomials[[\n",
    "        'k',\n",
    "        'k1',\n",
    "        'k2',\n",
    "        'k3',\n",
    "        'k4',\n",
    "        'k5',\n",
    "        'k6',\n",
    "        'k7'\n",
    "    ]],\n",
    "    id_vars = 'k'\n",
    ")\n",
    "melted_binomials['variable'] = melted_binomials['variable'].apply(lambda x: distribution_dict[x])\n",
    "\n",
    "fig,ax = plt.subplots(figsize = (7,3))\n",
    "g = sns.lineplot(\n",
    "    data = melted_binomials,\n",
    "    x = 'k',\n",
    "    y = 'value',\n",
    "    hue = 'variable',\n",
    ")\n",
    "g.set_xticks([k[0] for k in k_sigma])\n",
    "g.set_title('Underlying Binomial Distributions')\n",
    "g.set_xlabel('Number of Times Eaten Out')\n",
    "g.set_ylabel('Probability')\n",
    "plt.grid()\n",
    "plt.legend(\n",
    "    title = '$Binom(n_i,p_i)$',\n",
    "    bbox_to_anchor=(1.05, 0.5),\n",
    "    loc=6,\n",
    "    borderaxespad=0.\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig('underlying_binomials.png', dpi = 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11f6a0b",
   "metadata": {},
   "source": [
    "## Simulate Distributions Based on Single Variable Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae404416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the feature you want to use for modification\n",
    "# var = 'gender_male'\n",
    "# var = 'race_Minority'\n",
    "var = 'marital_status_Single'\n",
    "\n",
    "og,zero,one = modify_probabilities(\n",
    "    ps,\n",
    "    ns,\n",
    "    scale,\n",
    "    k_sigma,\n",
    "    meals_train,\n",
    "    factor_scale = 0.15,\n",
    "    factor_direction = -1,\n",
    "    variable = var,\n",
    "    new_scale = False\n",
    ")\n",
    "\n",
    "var_test = X_test.groupby(var)['num_meals_not_home'].value_counts(normalize = True).to_frame('prob').reset_index()\n",
    "var_test.columns = [var,'k','prob']\n",
    "# The printed output are the modified probabilities (f indicates 0 and m indicates 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bff232",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_acc = pd.merge(\n",
    "    zero,\n",
    "    var_test[var_test[var] == 0],\n",
    "    on = 'k'\n",
    ")\n",
    "zero_error = zero_acc[['prob_x','prob_y']].min(axis = 1).sum()\n",
    "\n",
    "one_acc = pd.merge(\n",
    "    one,\n",
    "    var_test[var_test[var] == 1],\n",
    "    on = 'k'\n",
    ")\n",
    "one_error = one_acc[['prob_x','prob_y']].min(axis = 1).sum()\n",
    "\n",
    "print('Accuracy')\n",
    "print(f'Test 0 H.I.: {np.round(zero_error,3)}')\n",
    "print(f'Test 1 H.I.: {np.round(one_error,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60ba2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (10,5))\n",
    "g = sns.lineplot(\n",
    "    data = og,\n",
    "    x = 'k',\n",
    "    y = 'prob',\n",
    "    color = lirio_brand_colors[2],\n",
    "    linestyle = '--',\n",
    "    ax = ax\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data = var_test[var_test[var] == 0],\n",
    "    x = 'k',\n",
    "    y = 'prob',\n",
    "    color = lirio_brand_colors[1],\n",
    "    linestyle = '-',\n",
    "    ax = ax\n",
    ")\n",
    "sns.lineplot(\n",
    "    data = zero,\n",
    "    x = 'k',\n",
    "    y = 'prob',\n",
    "    color = lirio_brand_colors[1],\n",
    "    linestyle = '--',\n",
    "    ax = ax\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data = var_test[var_test[var] == 1],\n",
    "    x = 'k',\n",
    "    y = 'prob',\n",
    "    color = lirio_brand_colors[0],\n",
    "    linestyle = '-',\n",
    "    ax = ax\n",
    ")\n",
    "sns.lineplot(\n",
    "    data = one,\n",
    "    x = 'k',\n",
    "    y = 'prob',\n",
    "    color = lirio_brand_colors[0],\n",
    "    linestyle = '--',\n",
    "    ax = ax\n",
    ")\n",
    "\n",
    "g.set_xticks(range(22))\n",
    "g.set_title('Modified Distributions')\n",
    "g.set_xlabel('Number of Times Eaten Out')\n",
    "g.set_ylabel('Probability')\n",
    "ax.legend(\n",
    "    labels = [\n",
    "        'Simulation',\n",
    "        f'Test: {feature_dict[var][0]}',\n",
    "        f'Modified: {feature_dict[var][0]}',\n",
    "        f'Test: {feature_dict[var][1]}',\n",
    "        f'Modified: {feature_dict[var][1]}',\n",
    "    ],\n",
    "    title = 'Data Source'\n",
    ")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{var}_modification.png', dpi = 250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3abc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same plot as above, but splitting into two subplots\n",
    "fig,ax = plt.subplots(figsize = (8,5), nrows = 2)\n",
    "sns.lineplot(\n",
    "    data = og,\n",
    "    x = 'k',\n",
    "    y = 'prob',\n",
    "    color = lirio_brand_colors[2],\n",
    "    linestyle = '--',\n",
    "    ax = ax[0]\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data = og,\n",
    "    x = 'k',\n",
    "    y = 'prob',\n",
    "    color = lirio_brand_colors[2],\n",
    "    linestyle = '--',\n",
    "    ax = ax[1]\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data = var_test[var_test[var] == 0],\n",
    "    x = 'k',\n",
    "    y = 'prob',\n",
    "    color = lirio_brand_colors[1],\n",
    "    linestyle = '-',\n",
    "    ax = ax[0]\n",
    ")\n",
    "sns.lineplot(\n",
    "    data = zero,\n",
    "    x = 'k',\n",
    "    y = 'prob',\n",
    "    color = lirio_brand_colors[1],\n",
    "    linestyle = '--',\n",
    "    ax = ax[0]\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data = var_test[var_test[var] == 1],\n",
    "    x = 'k',\n",
    "    y = 'prob',\n",
    "    color = lirio_brand_colors[0],\n",
    "    linestyle = '-',\n",
    "    ax = ax[1]\n",
    ")\n",
    "sns.lineplot(\n",
    "    data = one,\n",
    "    x = 'k',\n",
    "    y = 'prob',\n",
    "    color = lirio_brand_colors[0],\n",
    "    linestyle = '--',\n",
    "    ax = ax[1]\n",
    ")\n",
    "\n",
    "ax[0].set_xlabel('Number of Times Eating Outside Home')\n",
    "ax[1].set_xlabel('Number of Times Eating Outside Home')\n",
    "ax[0].set_ylabel('Probability')\n",
    "ax[1].set_ylabel('Probability')\n",
    "plt.suptitle('Modified Distributions')\n",
    "\n",
    "ax[0].legend(\n",
    "    labels = [\n",
    "        'Simulation',\n",
    "        f'Test: {feature_dict[var][0]}',\n",
    "        f'Modified: {feature_dict[var][0]}',\n",
    "    ],\n",
    ")\n",
    "ax[1].legend(\n",
    "    labels = [\n",
    "        'Simulation',\n",
    "        f'Test: {feature_dict[var][1]}',\n",
    "        f'Modified: {feature_dict[var][1]}',\n",
    "    ]\n",
    ")\n",
    "\n",
    "ax[0].set_xticks(range(22))\n",
    "ax[1].set_xticks(range(22))\n",
    "ax[0].grid()\n",
    "ax[1].grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{var}_modification_two_plots.png', dpi = 250)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
